# EMBENDDIGS

## üî∑ O que √© um *embedding*?

![image](https://github.com/user-attachments/assets/abaed47c-4c99-4d31-aa86-cd89ce1e32b4)

Um **embedding** √© uma representa√ß√£o vetorial densa e de baixa dimens√£o de um dado (texto, imagem, tempo, etc.), projetada para **capturar semelhan√ßas sem√¢nticas ou estruturais** em um espa√ßo num√©rico cont√≠nuo.

* Transforma dados complexos ‚Üí em vetores num√©ricos.
* Vetores semelhantes representam **itens semelhantes**.
* Muito usado em **NLP, machine learning, busca sem√¢ntica, recomenda√ß√£o e clustering**.

---

## üî∑ Tipos principais de embeddings (por tipo de dado)

| Tipo de Dado         | Exemplos                        | T√©cnicas / Modelos comuns                 |
| -------------------- | ------------------------------- | ----------------------------------------- |
| **Texto**            | Palavras, frases, documentos    | Word2Vec, BERT, Sentence-BERT, GPT        |
| **Imagem**           | Fotos, gr√°ficos                 | ResNet, CLIP, DINO, EfficientNet          |
| **√Åudio**            | Voz, m√∫sica, sons               | Wav2Vec, Whisper, YAMNet                  |
| **V√≠deo**            | V√≠deos curtos ou longos         | TimeSformer, ViViT                        |
| **C√≥digo**           | C√≥digo-fonte                    | CodeBERT, CodeT5                          |
| **Tabelas**          | Dados estruturados (tipo CSV)   | Entity embeddings, TabNet, TabTransformer |
| **Multimodal**       | Combina√ß√£o (ex: texto + imagem) | CLIP, GPT-4V, Gemini, FLAVA               |
| **S√©ries Temporais** | Dados sequenciais no tempo      | TS2Vec, LSTM autoencoders, T2Vec          |

---

## üî∑ Como os embeddings s√£o usados?

1. **Busca sem√¢ntica** ‚Äî Ex: encontrar documentos ou a√ß√µes parecidas.
2. **Clustering / agrupamento** ‚Äî Ex: identificar grupos de ativos com comportamento similar.
3. **Classifica√ß√£o** ‚Äî Embeddings como entrada para modelos supervisionados.
4. **Redu√ß√£o de dimensionalidade / visualiza√ß√£o** ‚Äî Usando t-SNE, UMAP.
5. **Recomenda√ß√£o** ‚Äî Ex: sugerir a√ß√µes, produtos ou estrat√©gias com base em perfil vetorial.

---

## üî∑ Embeddings para dados financeiros, trades e s√©ries temporais

### 1. **S√©ries Temporais Financeiras**

üîπ Ex: pre√ßos de a√ß√µes, volume, indicadores t√©cnicos
üîπ T√©cnicas:

* `TS2Vec`, `T2Vec` ‚Äì geram embeddings de janelas temporais
* **Autoencoders LSTM**
* **Transformers temporais**

üìå Usos: clusterizar ativos, prever regimes de mercado, busca por padr√µes.

---

### 2. **Dados de Trade e Book de Ordens**

üîπ Ex: logs de compra/venda, ordens, execu√ß√£o
üîπ T√©cnicas:

* **Entity Embeddings** para colunas categ√≥ricas
* **TabNet**, **SAINT**, **TabTransformer** para dados estruturados

üìå Usos: prever lucratividade de trades, modelar comportamento de mercado.

---

### 3. **Textos Financeiros**

üîπ Ex: relat√≥rios de empresas, not√≠cias, balan√ßos
üîπ Modelos:

* **FinBERT**, **BloombergGPT**, **FinancialBERT**

üìå Usos: an√°lise de sentimento, risco, embasamento para decis√µes quantitativas.

---

### 4. **Multimodal Financeiro**

üîπ Combina pre√ßo + texto + indicadores
üîπ T√©cnicas: redes que integram embeddings de diferentes tipos

üìå Usos: modelos mais ricos para predi√ß√£o ou an√°lise de ativos.

---

## ‚úÖ **Principais modelos de embeddings** (texto, imagens, s√©ries temporais)

### üîπ **Textuais ‚Äì Hugging Face / SentenceTransformers**

| Nome do Modelo                          | Tipo                  | Idioma         | Coment√°rio                                     |
| --------------------------------------- | --------------------- | -------------- | ---------------------------------------------- |
| `all-MiniLM-L6-v2`                      | Frases                | üá∫üá∏ Ingl√™s    | Leve e r√°pido, muito usado                     |
| `all-mpnet-base-v2`                     | Frases                | üá∫üá∏ Ingl√™s    | Alta performance em similaridade sem√¢ntica     |
| `paraphrase-multilingual-MiniLM-L12-v2` | Frases                | üåç Multil√≠ngue | Compacto e vers√°til                            |
| `paraphrase-multilingual-mpnet-base-v2` | Frases                | üåç Multil√≠ngue | Alta qualidade                                 |
| `bert-base-uncased`                     | Palavras              | üá∫üá∏ Ingl√™s    | Base do BERT                                   |
| `sentence-transformers/gtr-t5-base`     | Texto para busca      | üá∫üá∏ Ingl√™s    | Muito usado em ranking e busca sem√¢ntica       |
| `hkunlp/instructor-xl`                  | Embeddings com tarefa | üá∫üá∏ Ingl√™s    | Usa instru√ß√µes no input para embeddings        |
| `text-embedding-ada-002` (OpenAI)       | Texto geral           | üåç Multi       | API da OpenAI, alta qualidade e multilinguagem |

---

### üñºÔ∏è **Imagem ‚Äì via Hugging Face**

| Nome do Modelo                 | Tipo           | Coment√°rio                                |
| ------------------------------ | -------------- | ----------------------------------------- |
| `openai/clip-vit-base-patch32` | Imagem + texto | Multimodal (imagem/texto no mesmo espa√ßo) |
| `facebook/dino-vits8`          | Imagem         | Auto-supervisionado, √≥tima generaliza√ß√£o  |

---

### üß† **S√©ries Temporais (timeseries embeddings)**

| Nome do Modelo           | Tipo                     | Coment√°rio                                     |
| ------------------------ | ------------------------ | ---------------------------------------------- |
| `TS2Vec`                 | S√©rie temporal           | SOTA para timeseries embeddings                |
| `T2Vec`                  | S√©rie temporal           | Similar ao Word2Vec, mas para s√©ries temporais |
| `Informer`, `Autoformer` | Temporal + Deep Learning | Forecasting com representa√ß√£o interna vetorial |

---

## üß™ Exemplo pr√°tico: embeddings de uma s√©rie temporal com `TS2Vec`

### üîß Instalar depend√™ncias:

```bash
pip install ts2vec
```

> Se `ts2vec` n√£o estiver dispon√≠vel diretamente no PyPI, voc√™ pode encontrar o reposit√≥rio [no GitHub oficial: yusugomori/TS2Vec](https://github.com/yusugomori/TS2Vec).

---

### üìâ Exemplo em Python:

```python
import numpy as np
from ts2vec import TS2Vec
import matplotlib.pyplot as plt

# Simula√ß√£o de s√©rie temporal: 100 dias, 4 vari√°veis (ex: pre√ßo, volume, RSI, MACD)
np.random.seed(42)
serie_temporal = np.random.randn(100, 4)

# Treinamento do modelo
model = TS2Vec(input_dims=4)
model.fit([serie_temporal], verbose=True)

# Extra√ß√£o do embedding (por janela temporal ou s√©rie completa)
embedding = model.encode([serie_temporal])[0]

print("Shape do embedding:", embedding.shape)

# Visualiza√ß√£o (opcional)
plt.plot(embedding[:, 0])
plt.title("Embedding (dimens√£o 0) da s√©rie temporal")
plt.xlabel("Tempo")
plt.ylabel("Valor do embedding")
plt.show()
```

---

### üîç Resultado:

* O embedding tem **dimens√µes \[tempo, embedding\_dim]** ‚Äî voc√™ obt√©m uma representa√ß√£o vetorial para cada ponto da s√©rie.
* Pode usar isso para: clustering, compara√ß√£o de ativos, detec√ß√£o de padr√µes, regime switching etc.

---
√ìtimo! Vamos criar um exemplo completo com dados **reais do mercado financeiro**, usando o `yfinance` para baixar os dados de uma a√ß√£o (ex: PETR4.SA) e gerar embeddings com `TS2Vec`.

---

## üìà Exemplo: Embeddings de s√©rie temporal da Petrobras (PETR4.SA)

### üîß Passo 1: Instalar depend√™ncias

```bash
pip install yfinance ts2vec matplotlib
```

> Se `ts2vec` n√£o estiver no PyPI, clone do GitHub:

```bash
git clone https://github.com/yusugomori/TS2Vec.git
cd TS2Vec
pip install -e .
```

---

### üíª Passo 2: C√≥digo completo em Python

```python
import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from ts2vec import TS2Vec

# Baixar dados da Petrobras (PETR4.SA)
ticker = yf.Ticker("PETR4.SA")
df = ticker.history(start="2022-01-01", end="2023-12-31")

# Selecionar colunas relevantes (pre√ßo e volume)
df = df[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()

# Normalizar os dados (escala semelhante para o modelo)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
data_scaled = scaler.fit_transform(df)

# Convertendo para formato esperado pelo TS2Vec
data_series = data_scaled.astype(np.float32)

# Treinar o modelo TS2Vec
model = TS2Vec(input_dims=data_series.shape[1])
model.fit([data_series], verbose=True)

# Gerar embeddings
embedding = model.encode([data_series])[0]  # Shape: [tempo, embedding_dim]

print("Shape do embedding:", embedding.shape)

# Visualizar a 1¬™ dimens√£o do embedding ao longo do tempo
plt.plot(embedding[:, 0])
plt.title("Embedding da PETR4 - Dimens√£o 0")
plt.xlabel("Dias")
plt.ylabel("Valor do embedding")
plt.grid(True)
plt.show()
```

---

### ‚úÖ O que esse c√≥digo faz:

* Baixa os dados da **a√ß√£o PETR4.SA** entre 2022 e 2023.
* Usa `Open`, `High`, `Low`, `Close`, e `Volume` como entrada.
* Treina o modelo `TS2Vec` para aprender um **embedding da s√©rie temporal**.
* Plota uma dimens√£o do embedding como exemplo.

---

### üîç O que voc√™ pode fazer com esse embedding:

* **Clusterizar ativos** similares.
* **Detectar regimes de mercado** (alta, baixa, lateraliza√ß√£o).
* **Comparar per√≠odos diferentes da mesma a√ß√£o** (similaridade temporal).
* Alimentar modelos de previs√£o ou aprendizado n√£o supervisionado.

---

### üíª Exemplo embedding de texto

```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased')

embeddings = model.encode(df.text)

```

---



